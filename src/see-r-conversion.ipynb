{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Converting R code to Python\n",
    "\n",
    "This notebook aims to answer number 2 of the assignment:\n",
    "\n",
    "2. Convert the R codes into Python Codes (use jupyter notebook).\n",
    "\n",
    "This is a direct translation of SEE.R file to python\n",
    "\n",
    "To look at the comparison between SEE-K-means and SEE-(Another Clustering), head to [main.ipynb](./main.ipynb)"
   ],
   "id": "440f1521273ef559"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Import Libraries",
   "id": "25e1f8eac9105a3c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-21T15:48:46.685341Z",
     "start_time": "2025-02-21T15:48:46.455163Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import gaussian_kde\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score"
   ],
   "id": "cb9915ec898a1223",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Define Function/s",
   "id": "7a3c1523eb91e5f1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-21T15:50:59.920244Z",
     "start_time": "2025-02-21T15:50:59.894859Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def See(arg1, tidy):\n",
    "    # Filter rows where ATC equals arg1\n",
    "    C09CA01 = tidy[tidy['ATC'] == arg1].copy()\n",
    "\n",
    "    # Make working copies\n",
    "    Drug_see_p0 = C09CA01.copy()\n",
    "    Drug_see_p1 = C09CA01.copy()\n",
    "\n",
    "    # Sort by 'pnr' and 'eksd' and create a lag of 'eksd' by group 'pnr'\n",
    "    Drug_see_p1.sort_values(by=['pnr', 'eksd'], inplace=True)\n",
    "    Drug_see_p1['prev_eksd'] = Drug_see_p1.groupby('pnr')['eksd'].shift(1)\n",
    "    Drug_see_p1 = Drug_see_p1.dropna(subset=['prev_eksd'])\n",
    "\n",
    "    # For each pnr group, randomly sample one row\n",
    "    Drug_see_p1 = Drug_see_p1.groupby('pnr', group_keys=False).apply(lambda x: x.sample(1))\n",
    "\n",
    "    # Keep only needed columns\n",
    "    Drug_see_p1 = Drug_see_p1[['pnr', 'eksd', 'prev_eksd']].copy()\n",
    "\n",
    "    # Compute the event interval (if eksd is datetime, compute days; otherwise, assume numeric)\n",
    "    if np.issubdtype(Drug_see_p1['eksd'].dtype, np.datetime64):\n",
    "        Drug_see_p1['event.interval'] = (Drug_see_p1['eksd'] - Drug_see_p1['prev_eksd']).dt.days\n",
    "    else:\n",
    "        Drug_see_p1['event.interval'] = Drug_see_p1['eksd'] - Drug_see_p1['prev_eksd']\n",
    "    Drug_see_p1['event.interval'] = pd.to_numeric(Drug_see_p1['event.interval'])\n",
    "\n",
    "    # --- ECDF Generation ---\n",
    "    # Compute the empirical CDF for event.interval\n",
    "    sorted_intervals = np.sort(Drug_see_p1['event.interval'].values)\n",
    "    n = len(sorted_intervals)\n",
    "    yvals = np.arange(1, n+1) / n\n",
    "    dfper = pd.DataFrame({'x': sorted_intervals, 'y': yvals})\n",
    "\n",
    "    # Retain the lower 80% of the ECDF\n",
    "    dfper_80 = dfper[dfper['y'] <= 0.8].copy()\n",
    "    ni = dfper_80['x'].max()  # maximum event interval in the 80% subset\n",
    "\n",
    "    # Plot ECDFs\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(12, 6))\n",
    "    axs[0].scatter(dfper_80['x'], dfper_80['y'])\n",
    "    axs[0].set_title(\"80% ECDF\")\n",
    "    axs[0].set_xlabel(\"event.interval\")\n",
    "    axs[0].set_ylabel(\"ECDF\")\n",
    "    axs[1].scatter(dfper['x'], dfper['y'])\n",
    "    axs[1].set_title(\"100% ECDF\")\n",
    "    axs[1].set_xlabel(\"event.interval\")\n",
    "    axs[1].set_ylabel(\"ECDF\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Plot frequency table for pnr counts\n",
    "    m1 = Drug_see_p1['pnr'].value_counts()\n",
    "    m1.plot(kind='bar', title=\"Frequency of pnr\")\n",
    "    plt.xlabel(\"pnr\")\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.show()\n",
    "\n",
    "    # Subset to rows with event.interval <= ni (using the same dataframe as before)\n",
    "    Drug_see_p2 = Drug_see_p1[Drug_see_p1['event.interval'] <= ni].copy()\n",
    "\n",
    "    # --- Density Estimation on Log(event.interval) ---\n",
    "    log_intervals = np.log(Drug_see_p2['event.interval'].values)\n",
    "    kde = gaussian_kde(log_intervals)\n",
    "    x1 = np.linspace(log_intervals.min(), log_intervals.max(), 100)\n",
    "    y1 = kde(x1)\n",
    "\n",
    "    plt.plot(x1, y1)\n",
    "    plt.title(\"Density of log(event.interval)\")\n",
    "    plt.xlabel(\"log(event.interval)\")\n",
    "    plt.ylabel(\"Density\")\n",
    "    plt.show()\n",
    "\n",
    "    # Prepare data for silhouette analysis: scale the density grid points\n",
    "    a = pd.DataFrame({'x': x1, 'y': y1})\n",
    "    scaler = StandardScaler()\n",
    "    a_scaled = scaler.fit_transform(a)\n",
    "\n",
    "    # --- Silhouette Analysis to determine optimal number of clusters ---\n",
    "    # Try clustering with k from 2 to 10 (or up to the number of points)\n",
    "    best_k = 2\n",
    "    best_score = -1\n",
    "    max_k = min(10, len(a_scaled))\n",
    "    for k in range(2, max_k + 1):\n",
    "        km = KMeans(n_clusters=k, random_state=1234)\n",
    "        labels = km.fit_predict(a_scaled)\n",
    "        score = silhouette_score(a_scaled, labels)\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_k = k\n",
    "    max_cluster = best_k\n",
    "\n",
    "    # --- K-means Clustering on the ECDF x-values ---\n",
    "    # Reshape x for clustering (one-dimensional)\n",
    "    kmeans = KMeans(n_clusters=max_cluster, random_state=1234)\n",
    "    dfper['cluster'] = kmeans.fit_predict(dfper[['x']])\n",
    "\n",
    "    # Compute summary statistics (min, max, median) on log(x) for each cluster\n",
    "    dfper['log_x'] = np.log(dfper['x'])\n",
    "    summary = dfper.groupby('cluster')['log_x'].agg(['min', 'max', 'median']).reset_index()\n",
    "    # Replace any -infinity with 0 if necessary\n",
    "    summary['min'] = summary['min'].replace(-np.inf, 0)\n",
    "    # Exponentiate to return to original scale\n",
    "    summary['Minimum'] = np.exp(summary['min'])\n",
    "    summary['Maximum'] = np.exp(summary['max'])\n",
    "    summary['Median'] = np.exp(summary['median'])\n",
    "    # Keep clusters with a positive median\n",
    "    summary = summary[summary['Median'] > 0]\n",
    "\n",
    "    # --- Cross-join with Drug_see_p1 and assign a cluster if event.interval falls within the cluster bounds ---\n",
    "    Drug_see_p1['key'] = 1\n",
    "    summary['key'] = 1\n",
    "    cross = pd.merge(Drug_see_p1, summary, on='key')\n",
    "    cross['Final_cluster'] = np.where(\n",
    "        (cross['event.interval'] >= cross['Minimum']) & (cross['event.interval'] <= cross['Maximum']),\n",
    "        cross['cluster'],\n",
    "        np.nan\n",
    "    )\n",
    "    results = cross.dropna(subset=['Final_cluster']).copy()\n",
    "    # Keep only the needed columns (using the cluster from ECDF, not Final_cluster, as in the R code)\n",
    "    results = results[['pnr', 'Median', 'cluster']]\n",
    "\n",
    "    # --- Choose the cluster with the highest frequency ---\n",
    "    if not results.empty:\n",
    "        top_cluster = results['cluster'].value_counts().idxmax()\n",
    "        t1 = results[results['cluster'] == top_cluster].iloc[[0]].copy()\n",
    "    else:\n",
    "        t1 = pd.DataFrame({'cluster': [0], 'Median': [np.nan]})\n",
    "\n",
    "    # --- Merge cluster results back into Drug_see_p1 ---\n",
    "    Drug_see_p1 = pd.merge(Drug_see_p1, results, on='pnr', how='left', suffixes=('', '_res'))\n",
    "    # Fill missing Median values with the top clusterâ€™s median and missing clusters with 0\n",
    "    top_median = t1['Median'].iloc[0] if not t1.empty else np.nan\n",
    "    Drug_see_p1['Median'] = Drug_see_p1['Median'].fillna(top_median)\n",
    "    Drug_see_p1['cluster'] = Drug_see_p1['cluster'].fillna(0)\n",
    "    # Compute a test column as the difference between event.interval and Median (rounded to one decimal)\n",
    "    Drug_see_p1['test'] = np.round(Drug_see_p1['event.interval'] - Drug_see_p1['Median'], 1)\n",
    "\n",
    "    # Keep only pnr, Median, and cluster in a separate dataframe\n",
    "    Drug_see_p3 = Drug_see_p1[['pnr', 'Median', 'cluster']].copy()\n",
    "\n",
    "    # --- Merge back with the original copy (Drug_see_p0) ---\n",
    "    Drug_see_p0 = pd.merge(Drug_see_p0, Drug_see_p3, on='pnr', how='left')\n",
    "    Drug_see_p0['Median'] = Drug_see_p0['Median'].fillna(top_median)\n",
    "    Drug_see_p0['cluster'] = Drug_see_p0['cluster'].fillna(0)\n",
    "\n",
    "    return Drug_see_p0\n"
   ],
   "id": "8b1851a3bf43cc96",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-21T15:51:01.955227Z",
     "start_time": "2025-02-21T15:51:01.946610Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def see_assumption(arg1):\n",
    "    # Ensure data is sorted by 'pnr' and 'eksd'\n",
    "    arg1 = arg1.sort_values(by=['pnr', 'eksd']).copy()\n",
    "\n",
    "    # Create lag column 'prev_eksd' for each patient group\n",
    "    arg1['prev_eksd'] = arg1.groupby('pnr')['eksd'].shift(1)\n",
    "\n",
    "    # Create a sequential prescription number for each patient (starting at 1)\n",
    "    arg1['p_number'] = arg1.groupby('pnr').cumcount() + 1\n",
    "\n",
    "    # Filter to keep only rows where p_number is 2 or higher\n",
    "    Drug_see2 = arg1[arg1['p_number'] >= 2].copy()\n",
    "\n",
    "    # Select only the needed columns\n",
    "    Drug_see2 = Drug_see2[['pnr', 'eksd', 'prev_eksd', 'p_number']]\n",
    "\n",
    "    # Calculate Duration as the difference in days between eksd and prev_eksd\n",
    "    Drug_see2['Duration'] = (Drug_see2['eksd'] - Drug_see2['prev_eksd']).dt.days\n",
    "\n",
    "    # Convert p_number to a categorical type (like a factor in R)\n",
    "    Drug_see2['p_number'] = Drug_see2['p_number'].astype('category')\n",
    "\n",
    "    # Create a boxplot of Duration versus p_number\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    sns.boxplot(x='p_number', y='Duration', data=Drug_see2, ax=ax)\n",
    "    ax.set_title(\"Boxplot of Duration by p_number\")\n",
    "\n",
    "    # Compute the median duration for each patient (pnr)\n",
    "    medians_of_medians = (\n",
    "        Drug_see2.groupby('pnr')['Duration']\n",
    "        .median()\n",
    "        .reset_index(name='median_duration')\n",
    "    )\n",
    "\n",
    "    # Plot a horizontal dashed red line for each patient's median duration\n",
    "    # (Note: This may add many lines if there are many patients.)\n",
    "    for med in medians_of_medians['median_duration']:\n",
    "        ax.axhline(y=med, color='red', linestyle='dashed', alpha=0.5)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    return fig"
   ],
   "id": "b30da0bd980cd242",
   "outputs": [],
   "execution_count": 14
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
